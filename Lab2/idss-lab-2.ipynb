{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лабораторна робота 2 з ІСППР (варіант 26(1))\n",
    "### Виконали студенти групи КІ-31мп Шабо О.А. та Сотник Д.C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import gc\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools as it\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools as it\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch GPU is available\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"PyTorch GPU is available\")\n",
    "else:\n",
    "    print(\"PyTorch GPU is not available\")\n",
    "DEVICE = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 10\n",
    "\n",
    "# Seed the RNG for all devices (both CPU and CUDA)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "# Set python seed\n",
    "random.seed(RANDOM_SEED)\n",
    "# Set numpy seed\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Worker initialization function for data loaders (simplest approach)\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = (torch.initial_seed() + worker_id) % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "g_train = torch.Generator().manual_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1278 entries, 0 to 1277\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Date    1278 non-null   object \n",
      " 1   Open    1278 non-null   float64\n",
      " 2   High    1278 non-null   float64\n",
      " 3   Low     1278 non-null   float64\n",
      " 4   Close   1278 non-null   object \n",
      " 5   Volume  1278 non-null   object \n",
      "dtypes: float64(3), object(3)\n",
      "memory usage: 60.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "\n",
    "df.head()\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dmytro Sotnyk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\extmath.py:1050: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "c:\\Users\\Dmytro Sotnyk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\extmath.py:1055: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "c:\\Users\\Dmytro Sotnyk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\extmath.py:1075: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(959, 319)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Close'] = pd.to_numeric(df['Close'], errors='coerce')\n",
    "df['Volume'] = pd.to_numeric(df['Volume'], errors='coerce')\n",
    "\n",
    "# Convert 'Date' to datetime (optional for modeling, but useful for analysis)\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Select features and target for modeling\n",
    "features = df[['Open', 'High', 'Low', 'Volume']]\n",
    "target = df['Close']\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "features_normalized = scaler.fit_transform(features)\n",
    "\n",
    "# Split the data\n",
    "split_index = len(df) // 4\n",
    "X_train = features_normalized[split_index:]\n",
    "y_train = target.values[split_index:]\n",
    "X_test = features_normalized[:split_index]\n",
    "y_test = target.values[:split_index]\n",
    "\n",
    "# Convert to tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)  # Reshaping for a single target\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "len(X_train_tensor), len(X_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, seq_length):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.seq_length = seq_length\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if x.dim() == 2:  # If there are only 2 dimensions (batch_size, features)\n",
    "            x = x.unsqueeze(1)  # Add a seq_length dimension\n",
    "        out, _ = self.rnn(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "    \n",
    "    def fit(self, X_train, y_train, X_test, y_test, learning_rate=0.01, num_epochs=100, batch_size=32, verbose=True, optimizer_class=optim.Adam, loss_fn=nn.MSELoss):\n",
    "        optimizer = optimizer_class(self.parameters(), lr=learning_rate)\n",
    "        criterion = loss_fn()\n",
    "\n",
    "        # Convert to tensor datasets\n",
    "        train_dataset = TensorDataset(X_train, y_train)\n",
    "        test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "        # Create data loaders\n",
    "        train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        train_losses = []\n",
    "        test_losses = []\n",
    "\n",
    "        for epoch in tqdm(range(num_epochs), disable=not verbose):\n",
    "            self.train()\n",
    "            train_loss = 0.0\n",
    "            for X_batch, y_batch in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self(X_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item() * X_batch.size(0)\n",
    "            train_loss /= len(train_loader.dataset)\n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            test_loss = self.evaluate(test_loader, criterion)\n",
    "            test_losses.append(test_loss)\n",
    "\n",
    "            if verbose and (epoch+1) % 10 == 0:\n",
    "                print(f'Epoch {epoch+1}/{num_epochs}, Training Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}')\n",
    "                \n",
    "        self.train_losses = train_losses\n",
    "        self.test_losses = test_losses\n",
    "        gc.collect()\n",
    "    \n",
    "    def plot_loss(self):\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(self.train_losses, label='Training Loss')\n",
    "        plt.plot(self.test_losses, label='Test Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Loss over Epochs')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    def evaluate(self, data_loader, criterion):\n",
    "        self.eval()\n",
    "        total_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in data_loader:\n",
    "                outputs = self(X_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                total_loss += loss.item() * X_batch.size(0)\n",
    "        return total_loss / len(data_loader.dataset)\n",
    "\n",
    "    @staticmethod\n",
    "    def find_best_parameters(X_train, y_train, X_test, y_test, parameter_grid):\n",
    "        # Split data into train/validation sets\n",
    "        best_loss = float('inf')\n",
    "        best_params = None\n",
    "        \n",
    "        for params in tqdm(list(it.product(*parameter_grid.values()))):\n",
    "            hidden_dim, seq_length, num_epochs, batch_size = params\n",
    "            input_dim = X_train.shape[-1]  # Assuming X_train is already appropriately shaped\n",
    "            output_dim = y_train.shape[-1]  # Assuming y_train is also appropriately shaped\n",
    "            \n",
    "            model = RNNModel(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, seq_length=seq_length)\n",
    "            model.fit(X_train, y_train, X_test, y_test, num_epochs=num_epochs, batch_size=batch_size, verbose=False)\n",
    "            \n",
    "            val_loss = model.evaluate(X_test, y_test)  # You would need to implement this method\n",
    "            \n",
    "            if val_loss < best_loss:\n",
    "                best_loss = val_loss\n",
    "                best_params = params\n",
    "                \n",
    "        print(f'Best parameters found: {best_params}, with validation loss: {best_loss}')\n",
    "        return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out, (hidden, cell) = self.lstm(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.gru = nn.GRU(input_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out, _ = self.gru(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.003000020980834961,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 81,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b9c05da30ac4401926994695bb0c8cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 9\u001b[0m\n\u001b[0;32m      1\u001b[0m parameter_grid \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhidden_dim\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m100\u001b[39m],\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseq_length\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m30\u001b[39m],\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_epochs\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m200\u001b[39m],\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m64\u001b[39m]\n\u001b[0;32m      6\u001b[0m }\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Assuming X and y are your datasets prepared accordingly\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m best_params \u001b[38;5;241m=\u001b[39m \u001b[43mRNNModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_best_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameter_grid\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[33], line 87\u001b[0m, in \u001b[0;36mRNNModel.find_best_parameters\u001b[1;34m(X_train, y_train, X_test, y_test, parameter_grid)\u001b[0m\n\u001b[0;32m     84\u001b[0m model \u001b[38;5;241m=\u001b[39m RNNModel(input_dim\u001b[38;5;241m=\u001b[39minput_dim, hidden_dim\u001b[38;5;241m=\u001b[39mhidden_dim, output_dim\u001b[38;5;241m=\u001b[39moutput_dim, seq_length\u001b[38;5;241m=\u001b[39mseq_length)\n\u001b[0;32m     85\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, X_test, y_test, num_epochs\u001b[38;5;241m=\u001b[39mnum_epochs, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 87\u001b[0m val_loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# You would need to implement this method\u001b[39;00m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val_loss \u001b[38;5;241m<\u001b[39m best_loss:\n\u001b[0;32m     90\u001b[0m     best_loss \u001b[38;5;241m=\u001b[39m val_loss\n",
      "Cell \u001b[1;32mIn[33], line 67\u001b[0m, in \u001b[0;36mRNNModel.evaluate\u001b[1;34m(self, data_loader, criterion)\u001b[0m\n\u001b[0;32m     65\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 67\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m X_batch, y_batch \u001b[38;5;129;01min\u001b[39;00m data_loader:\n\u001b[0;32m     68\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(X_batch)\n\u001b[0;32m     69\u001b[0m         loss \u001b[38;5;241m=\u001b[39m criterion(outputs, y_batch)\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "parameter_grid = {\n",
    "    'hidden_dim': [20, 50, 100],\n",
    "    'seq_length': [10, 20, 30],\n",
    "    'num_epochs': [50, 100, 200],\n",
    "    'batch_size': [16, 32, 64]\n",
    "}\n",
    "\n",
    "# Assuming X and y are your datasets prepared accordingly\n",
    "best_params = RNNModel.find_best_parameters(X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor, parameter_grid)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
