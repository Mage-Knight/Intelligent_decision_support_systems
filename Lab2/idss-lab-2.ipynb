{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJMrECOskLWl"
      },
      "source": [
        "## Лабораторна робота 2 з ІСППР (варіант 26(1))\n",
        "### Виконали студенти групи КІ-31мп Шабо О.А. та Сотник Д.C."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "9szEf9FgkLWo"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import random\n",
        "import gc\n",
        "import os\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import itertools as it\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools as it\n",
        "\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpeh5cLDkLWq",
        "outputId": "a8ba21ca-2d00-441e-b9d4-91d09432e2a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch GPU is available\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    print(\"PyTorch GPU is available\")\n",
        "else:\n",
        "    print(\"PyTorch GPU is not available\")\n",
        "DEVICE = \"cuda\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "zD-cCCa6kLWq"
      },
      "outputs": [],
      "source": [
        "RANDOM_SEED = 10\n",
        "\n",
        "# Seed the RNG for all devices (both CPU and CUDA)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "# Set python seed\n",
        "random.seed(RANDOM_SEED)\n",
        "# Set numpy seed\n",
        "np.random.seed(RANDOM_SEED)\n",
        "\n",
        "torch.cuda.manual_seed_all(RANDOM_SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "os.environ['PYTHONHASHSEED'] = str(RANDOM_SEED)\n",
        "\n",
        "# Worker initialization function for data loaders (simplest approach)\n",
        "def seed_worker(worker_id):\n",
        "    worker_seed = (torch.initial_seed() + worker_id) % 2**32\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "\n",
        "g_train = torch.Generator().manual_seed(RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXqUinQBkLWr",
        "outputId": "9085cd6c-941d-4404-b25e-4fa06c233d1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1278 entries, 0 to 1277\n",
            "Data columns (total 6 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   Date    1278 non-null   object \n",
            " 1   Open    1278 non-null   float64\n",
            " 2   High    1278 non-null   float64\n",
            " 3   Low     1278 non-null   float64\n",
            " 4   Close   1278 non-null   object \n",
            " 5   Volume  1278 non-null   object \n",
            "dtypes: float64(3), object(3)\n",
            "memory usage: 60.0+ KB\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('train.csv')\n",
        "\n",
        "df.head()\n",
        "\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_npYnv7xHwQ",
        "outputId": "5def0067-6809-4999-e389-4fbe447f6a7f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0       663.59\n",
              "1       666.45\n",
              "2       657.21\n",
              "3       648.24\n",
              "4       620.76\n",
              "         ...  \n",
              "1273    835.67\n",
              "1274    832.15\n",
              "1275    823.31\n",
              "1276    802.32\n",
              "1277    796.79\n",
              "Name: Close, Length: 1278, dtype: object"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['Close']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "zxKzIe9okLWs"
      },
      "outputs": [],
      "source": [
        "df['Close'] = pd.to_numeric(df['Close'].str.replace(',', ''), errors='coerce')\n",
        "df['Volume'] = pd.to_numeric(df['Volume'].str.replace(',', ''), errors='coerce')\n",
        "\n",
        "# Convert 'Date' to datetime (optional for modeling, but useful for analysis)\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "# Select features and target for modeling\n",
        "features = df[['Open', 'High', 'Low', 'Volume']]\n",
        "target = df['Close']\n",
        "\n",
        "# Normalize features\n",
        "scaler = StandardScaler()\n",
        "features_normalized = scaler.fit_transform(features)\n",
        "\n",
        "# Split the data\n",
        "split_index = int(len(df) * 0.75)\n",
        "X_train = features_normalized[:split_index]\n",
        "y_train = target.values[:split_index]\n",
        "X_test = features_normalized[split_index:]\n",
        "y_test = target.values[split_index:]\n",
        "\n",
        "# Convert to tensors\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)  # Reshaping for a single target\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWM5HMYSnSwB",
        "outputId": "8c94ade8-dad3-43f1-b0cb-f8fdac8a8ffc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([958, 4])"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_tensor.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZUpim50nCj5",
        "outputId": "cb040991-b49f-4c0e-8014-74ca28595abf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([958, 1])"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train_tensor.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uj0DwS1Hw-_r",
        "outputId": "91424a76-02f1-4fba-83b6-dd02be5f9fd0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 663.59,  666.45,  657.21,  648.24,  620.76,  621.43,  624.25,\n",
              "        627.92,  623.28,  626.86,  631.18,  637.82,  584.39,  583.92,\n",
              "        579.34,  567.93,  566.54,  578.39,  576.11,  578.52,  579.24,\n",
              "        583.51,  594.7 ,  607.42,  605.11,  608.18,  609.79,  604.25,\n",
              "        610.52,  608.09,  603.9 ,  604.86,  602.98,  612.32,  606.28,\n",
              "        604.45,  608.23,  607.64,  616.7 ,  616.56,  620.7 ,  619.55,\n",
              "        612.57,  603.3 ,  605.14,  605.48,  598.61,  603.49,  616.09,\n",
              "        614.3 ,  619.43,  623.33,  632.24,  631.76,  638.23,  644.28,\n",
              "        640.83,  647.55,  645.25,  653.96,  646.63,  639.48,  645.15,\n",
              "        640.86,  633.41,  630.59,  629.11,  625.14,  634.22,  649.23,\n",
              "        622.89,  604.41,  607.9 ,  605.79,  597.66,  594.43,  595.96,\n",
              "        599.62,  608.05,  613.78,  613.3 ,  603.19,  602.78,  605.6 ,\n",
              "        609.35,  595.34,  605.89,  611.11,  607.48,  611.98,  603.57,\n",
              "        602.35,  609.44,  627.21,  621.34,  598.76,  612.43,  599.16,\n",
              "        607.79,  602.01,  589.91,  592.71,  586.62,  579.27,  569.42,\n",
              "        577.01,  568.85,  578.98,  576.65,  578.86,  566.94,  563.55,\n",
              "        559.55,  557.52,  562.96,  569.29,  579.94,  575.93,  563.66,\n",
              "        569.92,  559.16,  563.13,  567.74,  562.76,  578.48,  578.88,\n",
              "        586.22,  594.29,  584.38,  584.41,  580.11,  569.63,  568.92,\n",
              "        574.94,  573.35,  575.15,  579.17,  591.44,  609.15,  613.82,\n",
              "        605.91,  606.33,  611.68,  633.22,  630.57,  631.24,  630.95,\n",
              "        627.03,  639.57,  641.06,  638.79,  640.47,  640.59,  640.24,\n",
              "        658.2 ,  666.83,  665.71,  671.03,  675.29,  673.69,  667.68,\n",
              "        675.33,  674.95,  676.77,  667.39,  675.4 ,  686.13,  679.81,\n",
              "        683.21,  679.18,  678.86,  697.49,  704.22,  698.85,  690.29,\n",
              "        688.99,  704.11,  707.74,  708.04,  716.31,  725.51,  726.13,\n",
              "        731.98,  747.33,  747.11,  751.4 ,  754.43,  752.43,  759.69,\n",
              "        754.92,  760.41,  765.95,  765.55,  755.77,  742.05,  742.52,\n",
              "        749.42,  742.71,  738.95,  742.66,  753.42,  693.1 ,  679.92,\n",
              "        676.81,  678.49,  675.45,  675.9 ,  673.3 ,  678.44,  685.71,\n",
              "        686.04,  681.09,  679.85,  665.29,  650.5 ,  661.21,  664.08,\n",
              "        657.25,  650.76,  645.49,  645.41,  666.38,  668.14,  664.05,\n",
              "        666.14,  659.34,  668.87,  681.8 ,  690.  ,  696.46,  693.35,\n",
              "        689.14,  685.94,  689.24,  682.34,  683.54,  694.97,  695.65,\n",
              "        700.78,  700.04,  718.81,  719.1 ,  718.14,  720.38,  713.67,\n",
              "        707.56,  706.93,  704.36,  698.09,  705.44,  721.27,  721.69,\n",
              "        735.95,  732.74,  731.29,  736.1 ,  739.45,  737.96,  721.27,\n",
              "        722.95,  713.23,  709.37,  702.58,  700.95,  739.47,  752.15,\n",
              "        751.61,  748.67,  751.62,  751.77,  753.62,  773.48,  756.94,\n",
              "        763.64,  768.06,  771.83,  783.22,  780.28,  778.56,  780.72,\n",
              "        785.66,  790.72,  804.64,  790.29,  793.35,  797.52,  788.6 ,\n",
              "        787.97,  797.59,  799.01,  803.98,  819.25,  836.3 ,  829.1 ,\n",
              "        830.32,  829.24,  832.53,  825.34,  823.05,  819.29,  812.07,\n",
              "        805.58,  809.1 ,  812.48,  809.04,  808.09,  807.42,  810.2 ,\n",
              "        800.46,  792.02,  799.  ,  810.81,  803.99,  792.89,  780.91,\n",
              "        772.73,  775.52,  788.02,  788.23,  787.89,  779.79,  791.2 ,\n",
              "        780.42,  763.81,  797.68,  797.92,  805.69,  811.22,  806.88,\n",
              "        799.23,  816.82,  822.31,  818.18,  827.34,  843.4 ,  859.19,\n",
              "        854.88,  871.24,  869.09,  877.82,  875.13,  884.67,  913.38,\n",
              "        901.4 ,  906.69,  906.04,  904.49,  886.98,  880.37,  870.93,\n",
              "        878.86,  865.93,  868.38,  868.83,  865.25,  856.75,  857.35,\n",
              "        862.27,  877.32,  887.78,  877.4 ,  869.59,  874.6 ,  872.64,\n",
              "        883.82,  898.15,  898.21,  882.32,  878.52,  867.41,  863.83,\n",
              "        871.26,  874.67,  877.96,  885.45,  879.89,  884.  ,  891.04,\n",
              "        902.61,  902.76,  903.51,  917.72,  920.47,  922.16,  917.09,\n",
              "        916.04,  908.19,  894.15,  908.21,  901.33,  900.43,  885.27,\n",
              "        882.93,  879.85,  888.48,  885.32,  901.74,  904.09,  902.52,\n",
              "        894.12,  888.21,  890.22,  887.97,  883.09,  878.84,  867.43,\n",
              "        857.31,  854.56,  863.28,  863.05,  866.95,  871.32,  867.83,\n",
              "        864.02,  847.82,  846.23,  853.09,  844.58,  858.02,  869.24,\n",
              "        877.15,  877.17,  885.62,  886.24,  893.74,  890.61,  886.64,\n",
              "        885.33,  883.68,  900.85,  895.93,  900.64,  884.07,  884.41,\n",
              "        874.83,  875.77,  873.99,  873.51,  884.57,  885.56,  873.69,\n",
              "        869.96,  863.37,  851.33,  853.52,  865.86,  869.6 ,  873.71,\n",
              "        879.6 ,  895.57,  886.36, 1008.64, 1000.55, 1004.24, 1028.59,\n",
              "       1022.74, 1012.42, 1012.22, 1033.4 , 1027.6 , 1027.76, 1024.23,\n",
              "       1023.3 , 1018.72, 1019.95, 1005.19, 1013.25, 1007.82, 1009.01,\n",
              "       1029.64, 1032.4 , 1030.73, 1028.73, 1022.39, 1019.51, 1031.24,\n",
              "       1029.06, 1043.07, 1055.51, 1060.2 , 1056.69, 1051.59, 1050.38,\n",
              "       1055.28, 1054.45, 1066.94, 1075.19, 1081.69, 1074.34, 1067.03,\n",
              "       1057.89, 1070.04, 1066.93, 1081.78, 1083.25, 1097.61, 1112.05,\n",
              "       1108.8 , 1114.4 , 1115.34, 1106.42, 1117.64, 1110.07, 1101.97,\n",
              "       1114.26, 1135.74, 1138.11, 1127.15, 1127.09, 1119.91, 1146.25,\n",
              "       1145.48, 1153.05, 1147.38, 1160.51, 1161.83, 1156.92, 1120.75,\n",
              "       1098.21, 1119.94, 1103.89, 1132.28, 1177.74, 1130.33, 1135.04,\n",
              "       1140.07, 1156.78, 1174.22, 1169.72, 1186.92, 1183.44, 1196.61,\n",
              "       1199.51, 1207.56, 1199.05, 1200.81, 1200.49, 1209.19, 1216.66,\n",
              "       1216.83, 1215.87, 1212.32, 1199.4 , 1211.58, 1214.92, 1216.27,\n",
              "       1211.46, 1208.25, 1196.7 , 1203.99, 1185.8 , 1169.59, 1188.84,\n",
              "       1207.94, 1195.97, 1193.88, 1179.8 , 1154.76, 1155.55, 1128.87,\n",
              "        556.93,  558.46,  555.45,  565.61,  565.45,  568.18,  541.65,\n",
              "        536.68,  553.38,  562.6 ,  539.47,  529.15,  531.06,  534.97,\n",
              "        555.02,  534.63,  527.17,  533.35,  525.5 ,  523.72,  514.77,\n",
              "        515.73,  526.26,  525.22,  529.9 ,  526.48,  526.36,  513.73,\n",
              "        508.56,  509.6 ,  517.31,  528.47,  531.63,  525.21,  518.56,\n",
              "        519.2 ,  527.41,  528.32,  537.46,  543.57,  551.19,  564.4 ,\n",
              "        560.14,  558.55,  558.36,  552.41,  543.45,  543.17,  552.38,\n",
              "        554.81,  560.58,  559.02,  557.31,  549.84,  550.25,  542.79,\n",
              "        541.52,  551.85,  553.38,  554.84,  563.4 ,  563.07,  577.07,\n",
              "        574.42,  575.66,  573.7 ,  581.07,  580.74,  583.13,  580.66,\n",
              "        569.53,  574.5 ,  569.54,  577.59,  583.27,  583.18,  581.06,\n",
              "        572.16,  593.45,  587.86,  593.11,  594.35,  591.73,  587.41,\n",
              "        588.98,  584.01,  585.81,  570.03,  564.52,  571.58,  563.52,\n",
              "        564.82,  561.82,  567.21,  566.33,  561.19,  573.21,  573.08,\n",
              "        571.91,  580.57,  585.25,  582.89,  581.77,  580.96,  578.61,\n",
              "        576.28,  569.44,  567.64,  570.03,  575.75,  576.36,  580.39,\n",
              "        584.48,  588.11,  579.42,  581.5 ,  579.76,  574.04,  571.53,\n",
              "        578.36,  583.17,  587.66,  594.45,  585.76,  579.54,  586.38,\n",
              "        573.49,  575.52,  574.78,  575.78,  566.71,  568.52,  573.7 ,\n",
              "        575.77,  562.2 ,  570.93,  559.34,  543.  ,  531.75,  536.47,\n",
              "        528.58,  523.07,  509.77,  519.41,  525.1 ,  531.25,  542.49,\n",
              "        538.3 ,  539.29,  547.4 ,  547.83,  548.8 ,  557.55,  553.7 ,\n",
              "        552.59,  544.43,  540.56,  539.53,  545.99,  548.78,  545.81,\n",
              "        543.89,  542.91,  535.04,  533.57,  535.52,  533.37,  536.03,\n",
              "        537.79,  539.6 ,  538.89,  540.35,  532.34,  532.29,  529.87,\n",
              "        535.84,  523.82,  525.54,  531.91,  524.62,  526.89,  517.24,\n",
              "        512.39,  494.03,  503.51,  509.7 ,  514.94,  523.43,  529.14,\n",
              "        527.32,  532.57,  528.88,  528.97,  524.96,  523.37,  512.46,\n",
              "        500.59,  499.73,  501.3 ,  494.81,  491.2 ,  494.82,  499.5 ,\n",
              "        500.42,  506.69,  505.51,  516.62,  532.93,  538.47,  533.74,\n",
              "        517.21,  508.6 ,  509.26,  533.06,  527.03,  527.79,  521.33,\n",
              "        526.14,  529.55,  526.38,  535.47,  534.5 ,  541.44,  547.51,\n",
              "        541.35,  538.22,  541.38,  537.47,  530.45,  534.62,  542.38,\n",
              "        553.96,  556.87,  569.78,  572.07,  571.8 ,  573.75,  566.13,\n",
              "        567.29,  553.49,  549.67,  553.99,  545.82,  552.99,  549.33,\n",
              "        557.97,  556.46,  558.83,  557.28,  568.63,  557.26,  553.65,\n",
              "        546.84,  550.52,  546.5 ,  541.07,  534.06,  535.3 ,  535.55,\n",
              "        540.13,  539.3 ,  538.53,  537.69,  528.94,  531.07,  532.34,\n",
              "        522.62,  533.91,  532.51,  537.89,  545.5 ,  563.51,  555.37,\n",
              "        553.68,  549.08,  537.34,  537.9 ,  540.78,  530.8 ,  524.22,\n",
              "        530.7 ,  538.22,  535.7 ,  529.04,  529.62,  538.4 ,  533.85,\n",
              "        532.3 ,  537.36,  539.27,  542.51,  540.11,  532.32,  539.79,\n",
              "        539.78,  532.11,  533.99,  539.18,  540.31,  536.7 ,  533.33,\n",
              "        526.83,  526.69,  536.69,  534.61,  532.33,  527.2 ,  528.15,\n",
              "        529.26,  536.73,  536.69,  538.19,  540.48,  537.84,  535.23,\n",
              "        531.69,  521.52,  520.51,  521.84,  523.4 ,  522.86,  525.02,\n",
              "        516.83,  520.68,  530.13,  546.55,  561.1 ,  560.22,  579.85,\n",
              "        672.93,  663.02,  662.3 ,  662.1 ,  644.28,  623.56,  627.26,\n",
              "        628.  ,  631.93,  632.59,  625.61,  631.21,  629.25,  643.78,\n",
              "        642.68,  635.3 ,  633.73,  660.78,  659.56,  656.45,  657.12,\n",
              "        660.87,  656.13,  660.9 ,  646.83,  612.48,  589.61,  582.06,\n",
              "        628.62,  637.61,  630.38,  618.25,  597.79,  614.34,  606.25,\n",
              "        600.7 ,  614.66,  612.72,  621.35,  625.77,  623.24,  635.14,\n",
              "        635.98,  642.9 ,  629.25,  635.44,  622.69,  622.36,  625.8 ,\n",
              "        611.97,  594.89,  594.97,  608.42,  611.29,  626.91,  641.47,\n",
              "        645.44,  642.36,  639.16,  643.61,  646.67,  652.3 ,  651.16,\n",
              "        661.74,  662.2 ,  666.1 ,  650.28,  642.61,  651.79])"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "EsR85XRykLWt"
      },
      "outputs": [],
      "source": [
        "class RNNModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, seq_length):\n",
        "        super(RNNModel, self).__init__()\n",
        "        self.rnn = nn.RNN(input_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        self.seq_length = seq_length\n",
        "\n",
        "    def forward(self, x):\n",
        "        if x.dim() == 2:  # If there are only 2 dimensions (batch_size, features)\n",
        "            x = x.unsqueeze(1)  # Add a seq_length dimension\n",
        "        out, _ = self.rnn(x)\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "    def fit(self, X_train, y_train, X_test, y_test, learning_rate=0.01,\n",
        "            num_epochs=100, batch_size=32, verbose=True, optimizer_class=optim.Adam,\n",
        "            loss_fn=nn.MSELoss):\n",
        "        optimizer = optimizer_class(self.parameters(), lr=learning_rate)\n",
        "        criterion = loss_fn()\n",
        "\n",
        "        # Convert to tensor datasets\n",
        "        train_dataset = TensorDataset(X_train, y_train)\n",
        "        test_dataset = TensorDataset(X_test, y_test)\n",
        "\n",
        "        # Create data loaders\n",
        "        train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size,\n",
        "                                  drop_last=True, worker_init_fn=seed_worker,\n",
        "                                  generator=g_train, shuffle=True)\n",
        "        test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size,\n",
        "                                 shuffle=False)\n",
        "\n",
        "        train_losses = []\n",
        "        test_losses = []\n",
        "\n",
        "        for epoch in tqdm(range(num_epochs), disable=not verbose):\n",
        "            self.train()\n",
        "            train_loss = 0.0\n",
        "            for X_batch, y_batch in train_loader:\n",
        "                optimizer.zero_grad()\n",
        "                outputs = self(X_batch)\n",
        "                loss = criterion(outputs, y_batch)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                train_loss += loss.item()\n",
        "            train_loss /= len(train_loader.dataset)\n",
        "            train_losses.append(train_loss)\n",
        "\n",
        "            test_loss = self.evaluate(test_loader, criterion)\n",
        "            test_losses.append(test_loss)\n",
        "\n",
        "            if verbose and (epoch+1) % 10 == 0:\n",
        "                print(f'Epoch {epoch+1}/{num_epochs}, Training Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}')\n",
        "\n",
        "        self.train_losses = train_losses\n",
        "        self.test_losses = test_losses\n",
        "        gc.collect()\n",
        "\n",
        "    def plot_loss(self):\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.plot(self.train_losses, label='Training Loss')\n",
        "        plt.plot(self.test_losses, label='Test Loss')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.title('Loss over Epochs')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "    def evaluate(self, data_loader, criterion):\n",
        "        self.eval()\n",
        "        total_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for X_batch, y_batch in data_loader:\n",
        "                outputs = self(X_batch)\n",
        "                loss = criterion(outputs, y_batch)\n",
        "                total_loss += loss.item()\n",
        "        return total_loss / len(data_loader.dataset)\n",
        "\n",
        "    @staticmethod\n",
        "    def find_best_parameters(X_train, y_train, X_test, y_test, parameter_grid,\n",
        "                             criterion = nn.MSELoss()):\n",
        "        # Split data into train/validation sets\n",
        "        best_loss = float('inf')\n",
        "        best_params = None\n",
        "\n",
        "        for params in tqdm(list(it.product(*parameter_grid.values()))):\n",
        "            hidden_dim, seq_length, num_epochs, batch_size = params\n",
        "            input_dim = X_train.shape[-1]  # Assuming X_train is already appropriately shaped\n",
        "            output_dim = y_train.shape[-1]  # Assuming y_train is also appropriately shaped\n",
        "\n",
        "            model = RNNModel(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, seq_length=seq_length)\n",
        "            model.fit(X_train, y_train, X_test, y_test, num_epochs=num_epochs, batch_size=batch_size, verbose=False)\n",
        "\n",
        "            test_dataset = TensorDataset(X_test, y_test)\n",
        "            test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size,\n",
        "                                    shuffle=False)\n",
        "            val_loss = model.evaluate(test_loader, criterion)\n",
        "\n",
        "            if val_loss < best_loss:\n",
        "                best_loss = val_loss\n",
        "                best_params = params\n",
        "\n",
        "        print(f'Best parameters found: {best_params}, with validation loss: {best_loss}')\n",
        "        return best_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "zXkw24FbkLWv"
      },
      "outputs": [],
      "source": [
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, (hidden, cell) = self.lstm(x)\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "xxmoGtj3kLWv"
      },
      "outputs": [],
      "source": [
        "class GRUModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(GRUModel, self).__init__()\n",
        "        self.gru = nn.GRU(input_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.gru(x)\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "7cd5209324a94ccb95f20f82774948f4",
            "02fcc02ce1894c0f98e75ad139ac225c",
            "5ed454b0bfda403281daff98be11f682",
            "a1e63052b71b4ad2852666bf2f9cbe43",
            "6bcc760916484d688b4ab99cf197b082",
            "919a3c8c32d0488b86478b6576ed0d6c",
            "af37a20446b94ea9911e69b7409fb1f8",
            "603ceda4f3f140e982a5dbb18dbb215a",
            "3d51ab8337d24154a19a9c847064a75c",
            "d246f8e47fbb49e29aec212cc1800555",
            "82178c4d12bd45cdab0013c0f86f4d60"
          ]
        },
        "id": "ggrJ1WKFkLWv",
        "outputId": "05f04dc8-d22f-4899-88f4-bdbe57a3a407"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7cd5209324a94ccb95f20f82774948f4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best parameters found: (20, 10, 10, 16), with validation loss: 23828.55771484375\n"
          ]
        }
      ],
      "source": [
        "parameter_grid = {\n",
        "    'hidden_dim': [20, 50, 100],\n",
        "    'seq_length': [10, 20, 30],\n",
        "    'num_epochs': [50, 100, 200],\n",
        "    'batch_size': [16, 32, 64]\n",
        "}\n",
        "\n",
        "# parameter_grid = {\n",
        "#     'hidden_dim': [20],\n",
        "#     'seq_length': [10],\n",
        "#     'num_epochs': [10],\n",
        "#     'batch_size': [16]\n",
        "# }\n",
        "\n",
        "best_params = RNNModel.find_best_parameters(X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor, parameter_grid)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "02fcc02ce1894c0f98e75ad139ac225c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_919a3c8c32d0488b86478b6576ed0d6c",
            "placeholder": "​",
            "style": "IPY_MODEL_af37a20446b94ea9911e69b7409fb1f8",
            "value": "100%"
          }
        },
        "3d51ab8337d24154a19a9c847064a75c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5ed454b0bfda403281daff98be11f682": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_603ceda4f3f140e982a5dbb18dbb215a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3d51ab8337d24154a19a9c847064a75c",
            "value": 1
          }
        },
        "603ceda4f3f140e982a5dbb18dbb215a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bcc760916484d688b4ab99cf197b082": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7cd5209324a94ccb95f20f82774948f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_02fcc02ce1894c0f98e75ad139ac225c",
              "IPY_MODEL_5ed454b0bfda403281daff98be11f682",
              "IPY_MODEL_a1e63052b71b4ad2852666bf2f9cbe43"
            ],
            "layout": "IPY_MODEL_6bcc760916484d688b4ab99cf197b082"
          }
        },
        "82178c4d12bd45cdab0013c0f86f4d60": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "919a3c8c32d0488b86478b6576ed0d6c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1e63052b71b4ad2852666bf2f9cbe43": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d246f8e47fbb49e29aec212cc1800555",
            "placeholder": "​",
            "style": "IPY_MODEL_82178c4d12bd45cdab0013c0f86f4d60",
            "value": " 1/1 [00:01&lt;00:00,  1.25s/it]"
          }
        },
        "af37a20446b94ea9911e69b7409fb1f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d246f8e47fbb49e29aec212cc1800555": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
